{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#how to setup rtmp server, please reference below url\n",
    "https://www.cnblogs.com/nowgood/p/ffmpegnginx.html\n",
    "\n",
    "#send rtmp data from pi4 to server, can use follow command\n",
    "ffmpeg -f v4l2 -r 24 -video_size vga -pix_fmt yuv420p12be -i /dev/video0 -b:v 500k -c:v h264_omx -preset ultrafast -an -f flv rtmp://52.80.130.52/live/123456\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gluoncv -i https://opentuna.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bokeh==1.3.1 -i https://opentuna.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import numpy as np\n",
    "import cv2\n",
    "import base64\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "import time\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "# sagemaker_endpoint_name = 'object-detection-2019-10-18-17-56-41-925'\n",
    "# sagemaker_endpoint = sagemaker.predictor.RealTimePredictor(sagemaker_endpoint_name)\n",
    "# sagemaker_endpoint.content_type = 'image/jpeg'\n",
    "from image_classification import ImageClassification\n",
    "imageClassification = ImageClassification()\n",
    "\n",
    "for i in range(10):\n",
    "    # use GluonCV\n",
    "    detect_start = time.time()\n",
    "    frame = cv2.imread('../images/1.jpg')\n",
    "    scores = imageClassification.classify_image(frame)\n",
    "    #print('scores:', scores)\n",
    "    detect_end = time.time()\n",
    "    print('detect time:', detect_end-detect_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoPlayer(object):\n",
    "    def __init__(self):\n",
    "        self._init = False\n",
    "        self._myImage = None\n",
    "        \n",
    "    def __call__(self, frame):\n",
    "        if frame is None:\n",
    "            return\n",
    "        if self._init is False:\n",
    "            self.init_display(frame)\n",
    "            self._init = True\n",
    "        else:\n",
    "            self.update_display(frame)\n",
    "\n",
    "    def init_display(self, frame):\n",
    "        assert frame is not None\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA) # because Bokeh expects a RGBA image\n",
    "#         frame=cv2.flip(frame, -1) # because Bokeh flips vertically\n",
    "        frame=cv2.flip(frame, 0) # because Bokeh flips vertically\n",
    "        width=frame.shape[1]\n",
    "        height=frame.shape[0]\n",
    "        p = figure(x_range=(0,width), y_range=(0,height), output_backend=\"webgl\", width=width, height=height)\n",
    "        self._myImage = p.image_rgba(image=[frame], x=0, y=0, dw=width, dh=height)\n",
    "        show(p, notebook_handle=True)\n",
    "    \n",
    "    def update_display(self, frame):\n",
    "        assert frame is not None\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "#         frame=cv2.flip(frame, -1)\n",
    "        frame=cv2.flip(frame, 0) \n",
    "        self._myImage.data_source.data['image']=[frame]\n",
    "        push_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_result_process(frame, classes, scores, pre_msg, pre_msg2):\n",
    "    thres = 0.5\n",
    "    cv2.putText(frame, str(classes[np.argmax(scores[0])])+':'+str(round(np.max(scores[0]), 2)), (10, 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, thickness=1, color=(255, 255, 255))\n",
    "    msg = pre_msg\n",
    "    msg2 = pre_msg2\n",
    "    return frame, msg, msg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "need add rtmp support for sagemaker, please follow this page\n",
    "https://answers.opencv.org/question/180776/build-opencv-with-ffmpeg-support/\n",
    "\"\"\"\n",
    "url=\"rtmp://52.81.133.221/live/123456\"\n",
    "\n",
    "vcap = cv2.VideoCapture(url)\n",
    "player = VideoPlayer()\n",
    "\n",
    "pre_msg = ''\n",
    "pre_msg2 = ''\n",
    "run_mode = 2  # 1 for original image, 2 for image classification\n",
    "fps = 8  # 24\n",
    "\n",
    "print(\"Video start\")\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    read_start = time.time()\n",
    "    if run_mode == 1:\n",
    "        for i in range(fps):\n",
    "            ret, frame = vcap.read()\n",
    "    elif run_mode == 2:\n",
    "        ret, frame = vcap.read()\n",
    "    read_end = time.time()\n",
    "#     print('read time:', read_end-read_start)\n",
    "\n",
    "    if frame is not None:\n",
    "        start = time.time()\n",
    "        frame = cv2.flip(frame, -1)\n",
    "        \n",
    "        # save image\n",
    "        if run_mode == 1:\n",
    "            filename = '../images/echo/frame_'+str(time.time())+'.jpg'\n",
    "            cv2.imwrite(filename, frame)\n",
    "\n",
    "            print(filename)\n",
    "\n",
    "        if run_mode == 2:\n",
    "            # use SageMaker\n",
    "            #with open(filename, 'rb') as image:\n",
    "            #    f = image.read()\n",
    "            #    b = bytearray(f)\n",
    "            #result = sagemaker_endpoint.predict(b)\n",
    "            #print(json.loads(result))\n",
    "\n",
    "            # use GluonCV\n",
    "            detect_start = time.time()\n",
    "            scores = imageClassification.classify_image(frame)\n",
    "            #print('scores:', scores)\n",
    "            detect_end = time.time()\n",
    "#             print('detect time:', detect_end-detect_start)\n",
    "\n",
    "            frame, msg, msg2 = detection_result_process(frame, imageClassification.classes, scores, pre_msg, pre_msg2)\n",
    "            #print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(detect_end)), 'msg:', msg)\n",
    "            #print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(detect_end)), 'msg2:', msg2)\n",
    "            pre_msg = msg\n",
    "            pre_msg2 = msg2\n",
    "\n",
    "            # Display the resulting frame\n",
    "            #cv2.imwrite(filename, frame)\n",
    "            player(frame)\n",
    "            end = time.time()\n",
    "            #print('all time:', end-start)\n",
    "\n",
    "            #t = 1\n",
    "            #time.sleep(t)\n",
    "            #vcap.set(cv2.CAP_PROP_POS_FRAMES, t*25)\n",
    "\n",
    "            #t = 0.2\n",
    "            #sleep_time = t-(end-start)\n",
    "            #if sleep_time >= 0:\n",
    "            #    time.sleep(sleep_time)\n",
    "            #    vcap.set(cv2.CAP_PROP_POS_FRAMES, sleep_time*25)\n",
    "\n",
    "            #skip_frame = max(0, 25-int(1/(end-start)))\n",
    "            #print('skip_frame:', skip_frame)\n",
    "            #if skip_frame > 0:\n",
    "            #    vcap.set(cv2.CAP_PROP_POS_FRAMES, skip_frame)\n",
    "\n",
    "        if run_mode == 1:\n",
    "            t = 1\n",
    "            time.sleep(t)\n",
    "#         elif run_mode == 2:\n",
    "#             t = 1/fps\n",
    "#             time.sleep(t)\n",
    "            \n",
    "        #vcap.set(cv2.CAP_PROP_POS_FRAMES, t*25)\n",
    "        #break\n",
    "\n",
    "        # Press q to close the video windows before it ends if you want\n",
    "        #if cv2.waitKey(22) & 0xFF == ord('q'):\n",
    "        #    break\n",
    "    else:\n",
    "        print(\"Frame is None\")\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "vcap.release()\n",
    "print(\"Video stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
